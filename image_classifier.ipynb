{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catch Basin Classifier\n",
    "An image classifier written in Python with Tensorflow. Classifies catch basins in 3 classes.\n",
    "\n",
    "The three classes are:\n",
    "* `blocked` ðŸ Š 0\n",
    "* `clear` ðŸ Š 1\n",
    "* `partial` ðŸ Š 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras import layers\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Average Image Size\n",
    "The average image size is computed to ensure that all images are of the same width and height. This will be done by resizing all the images to the average dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "widths = []\n",
    "heights = []\n",
    "\n",
    "for path in glob(\"data/**/*.JPG\"):\n",
    "    with Image.open(path) as img:\n",
    "        widths.append(img.width)\n",
    "        heights.append(img.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(554, 732)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size = round(sum(widths) / len(widths)), round(sum(heights) / len(heights))\n",
    "image_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data\n",
    "Load the data and split into two groups: *training* and *validation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 82 files belonging to 3 classes.\n",
      "Using 66 files for training.\n",
      "Found 82 files belonging to 3 classes.\n",
      "Using 16 files for validation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['blocked', 'clear', 'partial']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset = tf.keras.utils.image_dataset_from_directory(\"data\", validation_split=0.2, subset=\"training\", seed=321, image_size=image_size)\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\"data\", validation_split=0.2, subset=\"validation\", seed=321, image_size=image_size)\n",
    "\n",
    "# Get list of classnames to verify that the class names were interpreted correctly\n",
    "training_dataset.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction of the Model\n",
    "Contruct a convolutional neural network. A `Rescaling` Layer is added to normalize `RGB` values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        (None, 554, 732, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 554, 732, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 277, 366, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 277, 366, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 138, 183, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 138, 183, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 69, 91, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 401856)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               51437696  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 51,461,667\n",
      "Trainable params: 51,461,667\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=(*image_size, 3)),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='tanh'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='tanh'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='tanh'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(3)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Begin training the model with `training_dataset` and `validation_dataset` for 15 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3/3 [==============================] - 16s 4s/step - loss: 27.5027 - accuracy: 0.3182 - val_loss: 4.9875 - val_accuracy: 0.2500\n",
      "Epoch 2/15\n",
      "3/3 [==============================] - 15s 4s/step - loss: 6.6552 - accuracy: 0.3333 - val_loss: 39.0493 - val_accuracy: 0.3125\n",
      "Epoch 3/15\n",
      "3/3 [==============================] - 15s 4s/step - loss: 26.5610 - accuracy: 0.4394 - val_loss: 17.7758 - val_accuracy: 0.3125\n",
      "Epoch 4/15\n",
      "3/3 [==============================] - 15s 4s/step - loss: 8.8910 - accuracy: 0.5455 - val_loss: 7.1778 - val_accuracy: 0.3750\n",
      "Epoch 5/15\n",
      "3/3 [==============================] - 15s 4s/step - loss: 3.7712 - accuracy: 0.5000 - val_loss: 8.3197 - val_accuracy: 0.4375\n",
      "Epoch 6/15\n",
      "3/3 [==============================] - 15s 4s/step - loss: 5.3176 - accuracy: 0.5758 - val_loss: 7.8941 - val_accuracy: 0.3750\n",
      "Epoch 7/15\n",
      "3/3 [==============================] - 15s 4s/step - loss: 5.8382 - accuracy: 0.5303 - val_loss: 7.8303 - val_accuracy: 0.3125\n",
      "Epoch 8/15\n",
      "3/3 [==============================] - 15s 4s/step - loss: 4.0792 - accuracy: 0.4848 - val_loss: 1.6429 - val_accuracy: 0.6875\n",
      "Epoch 9/15\n",
      "3/3 [==============================] - 15s 4s/step - loss: 1.2919 - accuracy: 0.7121 - val_loss: 3.4967 - val_accuracy: 0.4375\n",
      "Epoch 10/15\n",
      "3/3 [==============================] - 15s 4s/step - loss: 1.5728 - accuracy: 0.6818 - val_loss: 2.2025 - val_accuracy: 0.7500\n",
      "Epoch 11/15\n",
      "3/3 [==============================] - 15s 4s/step - loss: 0.8683 - accuracy: 0.8636 - val_loss: 2.6546 - val_accuracy: 0.5000\n",
      "Epoch 12/15\n",
      "3/3 [==============================] - 15s 4s/step - loss: 0.8846 - accuracy: 0.7727 - val_loss: 1.2216 - val_accuracy: 0.6875\n",
      "Epoch 13/15\n",
      "3/3 [==============================] - 15s 4s/step - loss: 0.3030 - accuracy: 0.8939 - val_loss: 0.8009 - val_accuracy: 0.8125\n",
      "Epoch 14/15\n",
      "3/3 [==============================] - 15s 4s/step - loss: 0.1795 - accuracy: 0.9242 - val_loss: 0.6655 - val_accuracy: 0.8750\n",
      "Epoch 15/15\n",
      "3/3 [==============================] - 14s 4s/step - loss: 0.0977 - accuracy: 0.9545 - val_loss: 0.8172 - val_accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "history = model.fit(\n",
    "  training_dataset,\n",
    "  validation_data=validation_dataset,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Analysis\n",
    "See how the model did. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out metrics such as accuracy and loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9545454382896423 val_accuracy: 0.875\n",
      "loss 0.09765702486038208 val_loss: 0.817203164100647\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "print('accuracy:', acc[-1], 'val_accuracy:', val_acc[-1])\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "print('loss', loss[-1], 'val_loss:', val_loss[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model\n",
    "Save the model so that it can be loaded again for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"saved_model\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2df7cac29cf8c954e3b838d1ae23efc6dc513b8c37df1857e4dd2dc61cf098bb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
