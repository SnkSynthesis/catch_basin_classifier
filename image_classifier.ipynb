{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catch Basin Classifier\n",
    "An image classifier written in Python with Tensorflow. Classifies catch basins in 3 classes.\n",
    "\n",
    "The three classes are:\n",
    "* `blocked` ðŸ Š 0\n",
    "* `clear` ðŸ Š 1\n",
    "* `partial` ðŸ Š 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras import layers\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import os\n",
    "import secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Average Image Size\n",
    "The average image size is computed to ensure that all images are of the same width and height. This will be done by resizing all the images to the average dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "widths = []\n",
    "heights = []\n",
    "\n",
    "for path in glob(\"data/**/*.JPG\"):\n",
    "    with Image.open(path) as img:\n",
    "        widths.append(img.width)\n",
    "        heights.append(img.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(554, 732)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size = round(sum(widths) / len(widths)), round(sum(heights) / len(heights))\n",
    "image_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data\n",
    "Load the data and split into two groups: *training* and *validation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60 files belonging to 3 classes.\n",
      "Using 48 files for training.\n",
      "Found 60 files belonging to 3 classes.\n",
      "Using 12 files for validation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['blocked', 'clear', 'partial']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset = tf.keras.utils.image_dataset_from_directory(\"data\", validation_split=0.2, subset=\"training\", seed=321, image_size=image_size)\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\"data\", validation_split=0.2, subset=\"validation\", seed=321, image_size=image_size)\n",
    "\n",
    "# Get list of classnames to verify that the class names were interpreted correctly\n",
    "training_dataset.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction of the Model\n",
    "Contruct a convolutional neural network. A `Rescaling` Layer is added to normalize `RGB` values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling_1 (Rescaling)      (None, 554, 732, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 554, 732, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 277, 366, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 277, 366, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 138, 183, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 138, 183, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 69, 91, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 401856)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               51437696  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 51,461,667\n",
      "Trainable params: 51,461,667\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=(*image_size, 3)),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(3, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Begin training the model with `training_dataset` and `validation_dataset` for 15 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 12s 4s/step - loss: 25.6786 - accuracy: 0.2917 - val_loss: 36.6655 - val_accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 12s 5s/step - loss: 23.8099 - accuracy: 0.3542 - val_loss: 7.1359 - val_accuracy: 0.3333\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 10s 4s/step - loss: 6.3756 - accuracy: 0.4792 - val_loss: 26.8977 - val_accuracy: 0.2500\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 12s 5s/step - loss: 17.7437 - accuracy: 0.3542 - val_loss: 7.0666 - val_accuracy: 0.4167\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 11s 4s/step - loss: 4.7804 - accuracy: 0.4167 - val_loss: 11.3857 - val_accuracy: 0.2500\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 11s 4s/step - loss: 7.1979 - accuracy: 0.5417 - val_loss: 17.2165 - val_accuracy: 0.2500\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 10s 4s/step - loss: 10.5515 - accuracy: 0.2708 - val_loss: 7.1006 - val_accuracy: 0.2500\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 11s 4s/step - loss: 4.6521 - accuracy: 0.4792 - val_loss: 6.8695 - val_accuracy: 0.2500\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 11s 4s/step - loss: 3.2944 - accuracy: 0.6667 - val_loss: 10.1077 - val_accuracy: 0.2500\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 10s 4s/step - loss: 1.7775 - accuracy: 0.6042 - val_loss: 6.4878 - val_accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "history = model.fit(\n",
    "  training_dataset,\n",
    "  validation_data=validation_dataset,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Analysis\n",
    "See how the model did. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out metrics such as accuracy and loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6041666865348816 val_accuracy: 0.3333333432674408\n",
      "loss 1.7774839401245117 val_loss: 6.487751483917236\n"
     ]
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "print('accuracy:', acc[-1], 'val_accuracy:', val_acc[-1])\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "print('loss', loss[-1], 'val_loss:', val_loss[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model\n",
    "Save the model so that it can be loaded again for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model\\assets\n"
     ]
    }
   ],
   "source": [
    "os.mkdir('saved_models')\n",
    "model.save(f'model-{secrets.token_hex(3)}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2df7cac29cf8c954e3b838d1ae23efc6dc513b8c37df1857e4dd2dc61cf098bb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
