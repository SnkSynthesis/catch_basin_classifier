{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catch Basin Classifier\n",
    "An image classifier written in Python with Tensorflow. Classifies catch basins in 3 classes.\n",
    "\n",
    "The three classes are:\n",
    "* `blocked` ðŸ Š 0\n",
    "* `clear` ðŸ Š 1\n",
    "* `partial` ðŸ Š 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras import layers\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Average Image Size\n",
    "The average image size is computed to ensure that all images are of the same width and height. This will be done by resizing all the images to the average dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "widths = []\n",
    "heights = []\n",
    "\n",
    "for path in glob(\"data/**/*.JPG\"):\n",
    "    with Image.open(path) as img:\n",
    "        widths.append(img.width)\n",
    "        heights.append(img.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(554, 732)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size = round(sum(widths) / len(widths)), round(sum(heights) / len(heights))\n",
    "image_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data\n",
    "Load the data and split into two groups: *training* and *validation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 47 files belonging to 3 classes.\n",
      "Using 38 files for training.\n",
      "Found 47 files belonging to 3 classes.\n",
      "Using 9 files for validation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['blocked', 'clear', 'partial']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset = tf.keras.utils.image_dataset_from_directory(\"data\", validation_split=0.2, subset=\"training\", seed=321, image_size=image_size)\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\"data\", validation_split=0.2, subset=\"validation\", seed=321, image_size=image_size)\n",
    "\n",
    "# Get list of classnames to verify that the class names were interpreted correctly\n",
    "training_dataset.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction of the Model\n",
    "Contruct a convolutional neural network. A `Rescaling` Layer is added to normalize `RGB` values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 554, 732, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 554, 732, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 277, 366, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 277, 366, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 138, 183, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 138, 183, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 69, 91, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 401856)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               51437696  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51,461,667\n",
      "Trainable params: 51,461,667\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=(*image_size, 3)),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='tanh'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='tanh'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='tanh'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(3)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Begin training the model with `training_dataset` and `validation_dataset` for 15 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2/2 [==============================] - 9s 2s/step - loss: 6.9179 - accuracy: 0.4444 - val_loss: 28.4356 - val_accuracy: 0.3750\n",
      "Epoch 2/15\n",
      "2/2 [==============================] - 10s 2s/step - loss: 24.3795 - accuracy: 0.3056 - val_loss: 11.2757 - val_accuracy: 0.5000\n",
      "Epoch 3/15\n",
      "2/2 [==============================] - 9s 2s/step - loss: 8.1466 - accuracy: 0.3056 - val_loss: 11.4136 - val_accuracy: 0.2500\n",
      "Epoch 4/15\n",
      "2/2 [==============================] - 12s 2s/step - loss: 11.3406 - accuracy: 0.3611 - val_loss: 9.7781 - val_accuracy: 0.3750\n",
      "Epoch 5/15\n",
      "2/2 [==============================] - 10s 1s/step - loss: 5.1447 - accuracy: 0.3333 - val_loss: 21.0636 - val_accuracy: 0.1250\n",
      "Epoch 6/15\n",
      "2/2 [==============================] - 12s 2s/step - loss: 8.6010 - accuracy: 0.5000 - val_loss: 9.8903 - val_accuracy: 0.5000\n",
      "Epoch 7/15\n",
      "2/2 [==============================] - 11s 2s/step - loss: 3.2619 - accuracy: 0.8056 - val_loss: 4.6953 - val_accuracy: 0.2500\n",
      "Epoch 8/15\n",
      "2/2 [==============================] - 11s 2s/step - loss: 2.4793 - accuracy: 0.5556 - val_loss: 3.1369 - val_accuracy: 0.2500\n",
      "Epoch 9/15\n",
      "2/2 [==============================] - 12s 2s/step - loss: 0.9861 - accuracy: 0.7778 - val_loss: 8.3020 - val_accuracy: 0.1250\n",
      "Epoch 10/15\n",
      "2/2 [==============================] - 11s 2s/step - loss: 2.2338 - accuracy: 0.7778 - val_loss: 4.8520 - val_accuracy: 0.5000\n",
      "Epoch 11/15\n",
      "2/2 [==============================] - 11s 2s/step - loss: 0.7516 - accuracy: 0.8889 - val_loss: 3.9308 - val_accuracy: 0.5000\n",
      "Epoch 12/15\n",
      "2/2 [==============================] - 14s 3s/step - loss: 1.0661 - accuracy: 0.7500 - val_loss: 4.8162 - val_accuracy: 0.2500\n",
      "Epoch 13/15\n",
      "2/2 [==============================] - 11s 2s/step - loss: 0.5533 - accuracy: 0.8889 - val_loss: 11.2063 - val_accuracy: 0.1250\n",
      "Epoch 14/15\n",
      "2/2 [==============================] - 11s 1s/step - loss: 2.1602 - accuracy: 0.6944 - val_loss: 4.5707 - val_accuracy: 0.3750\n",
      "Epoch 15/15\n",
      "2/2 [==============================] - 12s 2s/step - loss: 0.1728 - accuracy: 0.9444 - val_loss: 8.4112 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "history = model.fit(\n",
    "  training_dataset,\n",
    "  validation_data=validation_dataset,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Analysis\n",
    "See how the model did. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out metrics such as accuracy and loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9444444179534912 val_accuracy: 0.5\n",
      "loss 0.17278875410556793 val_loss: 8.411188125610352\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "print('accuracy:', acc[-1], 'val_accuracy:', val_acc[-1])\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "print('loss', loss[-1], 'val_loss:', val_loss[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model\n",
    "Save the model so that it can be loaded again for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"saved_model\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2df7cac29cf8c954e3b838d1ae23efc6dc513b8c37df1857e4dd2dc61cf098bb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
